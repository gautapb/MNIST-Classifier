{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *\n",
    "import seaborn as sns\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#downloading the MNIST dataset\n",
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/storage/data/mnist_png'),\n",
       " (#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the training datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#training images = 60,000\n",
    "Each of the categories having roughly equal distribution: train_y.unique(return_counts=True)\n",
    "'''\n",
    "train_images_list = get_image_files(path/'training')\n",
    "train_x_list = [tensor(Image.open(img_path)) for img_path in train_images_list]\n",
    "train_y_list = [int(img_path.parent.name) for img_path in train_images_list]\n",
    "train_x = (torch.stack(train_x_list).float()/255).view(-1,28*28)\n",
    "train_y = tensor(train_y_list).view(-1,1)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the validation datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#validation images = 10,000\n",
    "Each of the categories having roughly equal distribution: valid_y.unique(return_counts=True)\n",
    "'''\n",
    "valid_images_list = get_image_files(path/'testing')\n",
    "valid_x_list = [tensor(Image.open(img_path)) for img_path in valid_images_list]\n",
    "valid_y_list = [int(img_path.parent.name) for img_path in valid_images_list]\n",
    "valid_x = (torch.stack(valid_x_list).float()/255).view(-1,28*28)\n",
    "valid_y = tensor(valid_y_list).view(-1,1)\n",
    "\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Using fastai packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.090940</td>\n",
       "      <td>3.860469</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this is just to get a sense of the accuracy using resnet18\n",
    "dls = ImageDataLoaders.from_folder(path, train='training',valid='testing')\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy, n_out=10)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Manual SGD & Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, batch_size=256)\n",
    "#valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# function to calculate loss\n",
    "def mnist_loss(pred, actual):\n",
    "    l = nn.CrossEntropyLoss()\n",
    "    return l(pred, actual.squeeze())\n",
    "\n",
    "# function to calculate gradient\n",
    "def calc_grad(xb, yb, model):\n",
    "    pred = model(xb)\n",
    "    loss = mnist_loss(pred, yb)\n",
    "    loss.backward()    \n",
    "    return loss\n",
    "\n",
    "# function to define accuracy\n",
    "def batch_accuracy(pred, actual):\n",
    "    digit_pred = pred.max(dim=1)[1]\n",
    "    return (digit_pred==actual.squeeze()).float().mean()\n",
    "\n",
    "#function to train 1 epoch and print average batch loss\n",
    "def train_epoch(model):\n",
    "    batch_loss = []\n",
    "    for xb,yb in train_dl:\n",
    "        batch_loss.append(calc_grad(xb, yb, model))\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return tensor(batch_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Simple 2 activations function NN\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0959)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random accuracy\n",
    "batch_accuracy(simple_net(valid_x),valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "opt = BasicOptim(simple_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#function to train model for multiple epochs\n",
    "def train_model(model,epochs):\n",
    "    print('{:<10}{:<15}{:<15}'.format('Epoch','Training Loss','Validation Accuracy'))\n",
    "    for i in range(epochs):\n",
    "        avg_bl = train_epoch(model)\n",
    "        print('{:<10}{:<15,.2f}{:<15,.2f}'.format(i,avg_bl.item(),batch_accuracy(model(valid_x),valid_y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Loss  Validation Accuracy\n",
      "0         2.30           0.11           \n",
      "1         2.30           0.12           \n",
      "2         2.29           0.15           \n",
      "3         2.29           0.19           \n",
      "4         2.28           0.23           \n",
      "5         2.27           0.27           \n",
      "6         2.26           0.31           \n",
      "7         2.25           0.33           \n",
      "8         2.24           0.35           \n",
      "9         2.23           0.38           \n",
      "10        2.22           0.39           \n",
      "11        2.20           0.41           \n",
      "12        2.19           0.42           \n",
      "13        2.17           0.42           \n",
      "14        2.15           0.43           \n",
      "15        2.13           0.43           \n",
      "16        2.10           0.44           \n",
      "17        2.08           0.45           \n",
      "18        2.04           0.46           \n",
      "19        2.01           0.47           \n",
      "20        1.97           0.48           \n",
      "21        1.93           0.50           \n",
      "22        1.88           0.52           \n",
      "23        1.84           0.54           \n",
      "24        1.78           0.56           \n",
      "25        1.73           0.59           \n",
      "26        1.67           0.61           \n",
      "27        1.62           0.64           \n",
      "28        1.55           0.66           \n",
      "29        1.49           0.67           \n",
      "30        1.43           0.68           \n",
      "31        1.37           0.68           \n",
      "32        1.31           0.69           \n",
      "33        1.25           0.69           \n",
      "34        1.19           0.69           \n",
      "35        1.14           0.69           \n",
      "36        1.09           0.69           \n",
      "37        1.04           0.69           \n",
      "38        0.99           0.69           \n",
      "39        0.95           0.70           \n",
      "40        0.92           0.70           \n",
      "41        0.88           0.71           \n",
      "42        0.85           0.71           \n",
      "43        0.82           0.71           \n",
      "44        0.80           0.72           \n",
      "45        0.78           0.72           \n",
      "46        0.75           0.73           \n",
      "47        0.73           0.73           \n",
      "48        0.71           0.73           \n",
      "49        0.70           0.74           \n",
      "50        0.68           0.74           \n",
      "51        0.67           0.75           \n",
      "52        0.65           0.75           \n",
      "53        0.64           0.75           \n",
      "54        0.63           0.76           \n",
      "55        0.61           0.76           \n",
      "56        0.60           0.77           \n",
      "57        0.59           0.77           \n",
      "58        0.58           0.77           \n",
      "59        0.58           0.78           \n",
      "60        0.57           0.78           \n",
      "61        0.56           0.78           \n",
      "62        0.55           0.79           \n",
      "63        0.54           0.79           \n",
      "64        0.54           0.79           \n",
      "65        0.53           0.80           \n",
      "66        0.52           0.80           \n",
      "67        0.52           0.80           \n",
      "68        0.51           0.80           \n",
      "69        0.51           0.81           \n",
      "70        0.50           0.81           \n",
      "71        0.50           0.81           \n",
      "72        0.49           0.81           \n",
      "73        0.49           0.82           \n",
      "74        0.48           0.82           \n",
      "75        0.48           0.82           \n",
      "76        0.48           0.82           \n",
      "77        0.47           0.83           \n",
      "78        0.47           0.83           \n",
      "79        0.46           0.83           \n",
      "80        0.46           0.83           \n",
      "81        0.46           0.83           \n",
      "82        0.45           0.83           \n",
      "83        0.45           0.84           \n",
      "84        0.45           0.84           \n",
      "85        0.44           0.84           \n",
      "86        0.44           0.84           \n",
      "87        0.44           0.84           \n",
      "88        0.44           0.84           \n",
      "89        0.43           0.85           \n",
      "90        0.43           0.85           \n",
      "91        0.43           0.85           \n",
      "92        0.43           0.85           \n",
      "93        0.42           0.85           \n",
      "94        0.42           0.85           \n",
      "95        0.42           0.85           \n",
      "96        0.42           0.85           \n",
      "97        0.41           0.85           \n",
      "98        0.41           0.85           \n",
      "99        0.41           0.86           \n"
     ]
    }
   ],
   "source": [
    "#model training call\n",
    "train_model(simple_net, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
